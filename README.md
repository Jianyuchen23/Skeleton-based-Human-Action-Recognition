# Skeleton-based-Human-Action-Recognition
This is partial implementation of PR 2017 and CVPR 2018 papers

Matlab R2015b, Python 2.7.14, and Pytorch 0.3.0 are used.

First, download Northwestern-UCLA dataset and NTU RGB+D dataset from here, and put dataset into current file.

Second, open Matlab and run "run.m" to extract feature for each sample.

Third, run "python run.py" for training and testing.

Finally, run "python show.py" to get final results.
